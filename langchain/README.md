# ChatGLM-6B-LangChain
本仓库提供了一个基于 ChatGLM-6B 模型实现的LangChain应用：基于给定PDF文件的内容回答问题。本仓库后续会加入更多的LangChain应用样例。

友情链接：

- [langchain-ChatGLM](https://github.com/imClumsyPanda/langchain-ChatGLM)：基于 langchain 的 ChatGLM 应用，实现基于可扩展知识库的问答

## 软件依赖
除 ChatGLM-6B 的依赖之外，需要安装langchain，可能还需要安装一些额外的依赖

```
pip install langchain tiktoken chromadb pytesseract pdf2image unstructured typing-inspect==0.8.0 typing_extensions==4.5.0
```
该样例基于Python 3.9与langchain 0.0.176，若使用Python 3.7或3.7以下版本，可能无法与langchain 0.0.176适配。

## 使用方法

### 参数设置
在pdfreader.py的第10-13行有四个可以调整的参数，分别是：

- chatglm_name_or_path：ChatGLM-6B 的模型版本，或者是本地模型路径
- embedder_name_or_path：句子编码模型的模型名字，或者是本地模型路径
- pdf_file_path：data/nk29.pdf是用来测试的PDF文件，也可以使用自己准备的PDF文件，在此处填入文件路径
- query：目标问题

```json
chatglm_name_or_path = 'THUDM/chatglm-6b'
embedder_name_or_path = 'GanymedeNil/text2vec-large-chinese'
pdf_file_path = './data/nk29.pdf'
query = "问答系统包含哪些主要模块？"
```

### 运行

使用以下指令运行该样例（基于CPU运行）：
```shell
python pdfreader.py
```
运行示例如下所示，其中，“文章”是从PDF中检索得到的证据片段，“问题“是用户的输入，“答案”是系统的生成结果。

```
根据文章内容回答问题。

文章:
处理好问答系统研究和问答系统实用之间的关系。目前我们的问答系统基本上都是针对具有简短答案的事实问题研发的,但这样的系统在实际应用中到底能够解决用户真正关心问题的百分之多少,或者说我们应该研究哪种类型问

经过这几年的发展,问答系统已经成为自然语言处理领域和信息检索领域的一个重要分支和新兴的研究热点,其

我们的汉语问答系统研发阶段 五、问答系统的基本原理 典型的问答系统通常由提问处理模块,检索模块和答案抽取模块三部分组成,如图

)的信息检索系统。因此,问答系统和根据关键词检索并返回相关文档集合的传统搜索引擎有着根本的区别。可以说,问答系统能够提供用户真正有用、精确的信息,它将是下一代的搜索引擎的理想选择之一。

所有问答技术的研究者在设计、研发问答技术的时候都会遇到同样一个问题:如何比较不同问答技术的优劣?问答系统评测平台即是完成这个任务,它对问答技术的发展有着很大的推动作用。目前,对问答系统进行评测的国际会

问题:问答系统包含哪些主要模块?
答案: 问答系统通常由提问处理模块、检索模块和答案抽取模块三部分组成。
```

## 更多的设置

除了上述参数以外，还有另外三个设置会对系统性能造成影响。

### Prompt

默认prompt如下：

```python
prompt = PromptTemplate(
            input_variables=["context", "question"],
            template="根据文章内容回答问题。\n文章：{context}\n问题：{question}\n答案："
        )
```

不同的prompt会带来不同的问答表现，上述prompt没有要求模型忠于PDF的内容，此时模型可能会根据模型内部的知识生成答案，例如下面的问答示例：

```
根据文章内容回答问题。
文章:Factoid、List问题已经回答的内容。 TREC QA Track 的评测指标主要有平均排序倒数(Mean Reciprocal Rank ,简称 MRR)、准确率(Accuracy )

我们认为:基于字符表层的文本分析技术(例如,模板技术)必须和快速、浅层自然语言处理技术有效结合,才能获得性能优良的问答系统。  TREC评测结果也说明,系统整体性能的优劣在很大程度上依赖于对

索技术于一身的新一代搜索引擎。它的出现旨在提供更有力的信息获取工具,以应对信息爆炸带来的严重挑战。经过这几年的发展,问答系统已经成为自然语言处理领域和信息检索领域的一个重要分支和新兴的研究热点,其

)后,人们对基于自然语言的问答系统再次产生了浓厚的兴趣,在近些年的 TREC比赛中,QA Track 是最受关注的评测项目之一。 从第一个英文问答系统STUDENT[40] ,到早期著名的LUNAR

1 表6.1 三类问答技术代表系统在 TREC评测中的成绩比较 七、应用于问答系统的自然语言处理技术

问题:ChatGPT的性能如何?

答案: 根据文章所述,ChatGPT在 TREC QA Track 评测中取得了不错的成绩,平均排序倒数和准确率都高于其他代表系统。ChatGPT采用了基于深度学习的自然语言处理技术,包括卷积神经网络(CNN)和循环神经网络(RNN)等,能够对自然语言文本进行深入的理解和分析,从而实现问答功能。此外,ChatGPT还采用了预训练和微调等技术,以提高系统的性能。总之,ChatGPT在自然语言处理领域取得了很好的成绩,并被认为是未来问答系统的重要研究方向之一。
```

可以将prompt更改为下面形式，即提醒模型拒绝无法回答的问题。

```python
prompt = PromptTemplate(
            input_variables=["context", "question"],
            template="文章：\n{context}\n\n问题：\n{question}\n\n文章内容能否回答该问题，输出“能”或者“不能”，若能回答，则同时输出答案："
        )
```

生成结果如下，可以看到，模型识别出无法回答该问题并给出了解释，但该解释也反映了模型的两个问题：（1）没有完全按照prompt的指示输出，prompt的控制力度不足；（2）生成了一些错误的事实。进行针对性的微调或提供少量的In-Context Examples可能可以缓解上述问题。

```
文章:
Factoid、List问题已经回答的内容。 TREC QA Track 的评测指标主要有平均排序倒数(Mean Reciprocal Rank ,简称 MRR)、准确率(Accuracy )

我们认为:基于字符表层的文本分析技术(例如,模板技术)必须和快速、浅层自然语言处理技术有效结合,才能获得性能优良的问答系统。  TREC评测结果也说明,系统整体性能的优劣在很大程度上依赖于对

索技术于一身的新一代搜索引擎。它的出现旨在提供更有力的信息获取工具,以应对信息爆炸带来的严重挑战。经过这几年的发展,问答系统已经成为自然语言处理领域和信息检索领域的一个重要分支和新兴的研究热点,其

)后,人们对基于自然语言的问答系统再次产生了浓厚的兴趣,在近些年的 TREC比赛中,QA Track 是最受关注的评测项目之一。 从第一个英文问答系统STUDENT[40] ,到早期著名的LUNAR

1 表6.1 三类问答技术代表系统在 TREC评测中的成绩比较 七、应用于问答系统的自然语言处理技术

问题:
ChatGPT的性能如何?

文章内容能否回答该问题,输出“能”或者“不能”,若能回答,则同时输出答案: 文章内容不能回答该问题,因为文章内容主要介绍了自然语言处理技术在信息检索领域的应用,而 ChatGPT 是一种人工智能助手,它的主要性能取决于其设计和训练数据的质量,而不是自然语言处理技术的性能。
```

### 文本分割策略

由于原始的PDF文本过长，需要对其进行分割，以适配ChatGLM的有效输入长度。在pdfreader.py中，默认使用了简单的滑动窗口式分割，这样的分割方式没有考虑句子的边界，可能会导致分割后的文本中包含不完整的句子。可以考虑首先对原始文本进行分句，然后再分割。

此外，默认情况下，多个滑动窗口之间没有重叠文本，这可能导致上下文信息的缺失。因此，可以考虑增大重叠文本的长度：

```python
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size = 100, # 滑动窗口大小
    chunk_overlap = 0 # 重叠的token数量
)
```

增大滑动窗口大小也可以缓解上下文信息缺失的问题，但增大这两个参数都可能引入更多的噪声，或增大ChatGLM的计算开销。因此需要在上下文信息、噪声、计算开销之间取一个平衡。

### 检索文本数量

默认情况下，检索得到文本片段的数量是5，增大该参数可以提升证据文本的召回率，但同时会降低精确率，引入更多的噪声。

```python
qa = VectorDBQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            vectorstore=docsearch,
            k=5, # 检索得到的证据文本数量
            chain_type_kwargs={"prompt": prompt}
        )
```

